{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae43e306-e5f1-4831-bb06-cecdb288fd12",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stockhaus/miniconda3/envs/sysgen/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import gc\n",
    "import os\n",
    "import pysam\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8be2f56b-e9fb-4abc-9339-a335bc412afa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from encoding_utils import sequence_encoders\n",
    "import helpers.train_eval as train_eval    #train and evaluation\n",
    "import helpers.misc as misc                #miscellaneous functions\n",
    "from models.spec_dss import DSSResNetEmb, SpecAdd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e12e119",
   "metadata": {},
   "source": [
    "# Train/Test Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff79b474",
   "metadata": {},
   "source": [
    "**0. Specify input parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4edc775a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_params = misc.dotdict({})\n",
    "\n",
    "input_params.dataset =  '../datasets/phase3_top10/dataset.parquet'\n",
    "input_params.model_weight = '../checkpoints/phase3_top10/aware_large_splitmsk/weights/epoch_100_weights_model.pt'\n",
    "#input_params.species_list = datadir + 'fasta/240_species/240_species.txt'\n",
    "\n",
    "input_params.output_dir = '../test'\n",
    "\n",
    "input_params.split_mask = False\n",
    "input_params.mask_rate = 0.2 #[0.012,0.2]#RAN #single float or 2 floats for reference and alternative\n",
    "input_params.masking = 'none' # stratified_maf or none\n",
    "\n",
    "input_params.test = True\n",
    "\n",
    "input_params.get_embeddings = True\n",
    "# input_params.get_embeddings = False\n",
    "input_params.mask_at_test = True\n",
    "\n",
    "input_params.agnostic = False\n",
    "\n",
    "input_params.seq_len = 5000\n",
    "\n",
    "input_params.tot_epochs = 1\n",
    "input_params.fold = 0\n",
    "input_params.Nfolds = 5\n",
    "\n",
    "input_params.train_splits = 1\n",
    "\n",
    "input_params.save_at = [1]\n",
    "input_params.validate_every = 1\n",
    "\n",
    "input_params.d_model = 256\n",
    "input_params.n_layers = 16\n",
    "input_params.dropout = 0.\n",
    "\n",
    "input_params.batch_size = 1\n",
    "input_params.learning_rate = 1e-4\n",
    "input_params.weight_decay = 0\n",
    "\n",
    "if input_params.dataset.endswith('.fa'):\n",
    "    seq_df = pd.read_csv(input_params.dataset + '.fai', header=None, sep='\\t', usecols=[0], names=['seq_name'])\n",
    "elif input_params.dataset.endswith('.parquet'):\n",
    "    seq_df = pd.read_parquet(input_params.dataset).reset_index()\n",
    "    \n",
    "seq_df[['split','sample_id','seg_name']] =  seq_df['seq_name'].str.split(':',expand=True)\n",
    "\n",
    "if not input_params.agnostic:\n",
    "    #for segment-aware model, assign a label to each segment\n",
    "    seg_name = seq_df.seq_name.apply(lambda x:':'.join(x.split(':')[2:]))\n",
    "    segment_encoding = seg_name.drop_duplicates().reset_index(drop=True)\n",
    "    segment_encoding = {seg_name:idx for idx,seg_name in segment_encoding.items()}\n",
    "    seq_df['seg_label'] = seg_name.map(segment_encoding)\n",
    "else:\n",
    "    seq_df['seg_label'] = 0\n",
    "\n",
    "\n",
    "if input_params.test:\n",
    "    seq_df = seq_df[seq_df.split=='test']\n",
    "else:\n",
    "    seq_df = seq_df[seq_df.split!='test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d126226b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq_name</th>\n",
       "      <th>seq</th>\n",
       "      <th>split</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>seg_name</th>\n",
       "      <th>seg_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20010</th>\n",
       "      <td>test:NA20795:ENSG00000198502.5</td>\n",
       "      <td>FBFFFFFRMRMMMFBFFMBRBRFFRFFFFFFFFMFFBFFFFFFFFB...</td>\n",
       "      <td>test</td>\n",
       "      <td>NA20795</td>\n",
       "      <td>ENSG00000198502.5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20011</th>\n",
       "      <td>test:HG00260:ENSG00000214425.1</td>\n",
       "      <td>RRBRRRBRRRBBRRBBBBRBBBRRBRBRRBRRRRBBBRBRRBBRRB...</td>\n",
       "      <td>test</td>\n",
       "      <td>HG00260</td>\n",
       "      <td>ENSG00000214425.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20012</th>\n",
       "      <td>test:HG01632:ENSG00000176681.9</td>\n",
       "      <td>BBRBBBRBBBBBBRBBBBRBBBBBBBBBBBBBBBBBRRBBBBRBBB...</td>\n",
       "      <td>test</td>\n",
       "      <td>HG01632</td>\n",
       "      <td>ENSG00000176681.9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20013</th>\n",
       "      <td>test:HG00173:ENSG00000238083.3</td>\n",
       "      <td>RMRRRRRRRRRRRRRRRRFRRRRFRRRRRRMRRRRMRRRRRRRMRR...</td>\n",
       "      <td>test</td>\n",
       "      <td>HG00173</td>\n",
       "      <td>ENSG00000238083.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20014</th>\n",
       "      <td>test:HG00178:ENSG00000229450.2</td>\n",
       "      <td>RRRRRRRRRRRRRRRRRRRRRRRRRRRRRRBBRRBRRRRRRRRRRR...</td>\n",
       "      <td>test</td>\n",
       "      <td>HG00178</td>\n",
       "      <td>ENSG00000229450.2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             seq_name  \\\n",
       "20010  test:NA20795:ENSG00000198502.5   \n",
       "20011  test:HG00260:ENSG00000214425.1   \n",
       "20012  test:HG01632:ENSG00000176681.9   \n",
       "20013  test:HG00173:ENSG00000238083.3   \n",
       "20014  test:HG00178:ENSG00000229450.2   \n",
       "\n",
       "                                                     seq split sample_id  \\\n",
       "20010  FBFFFFFRMRMMMFBFFMBRBRFFRFFFFFFFFMFFBFFFFFFFFB...  test   NA20795   \n",
       "20011  RRBRRRBRRRBBRRBBBBRBBBRRBRBRRBRRRRBBBRBRRBBRRB...  test   HG00260   \n",
       "20012  BBRBBBRBBBBBBRBBBBRBBBBBBBBBBBBBBBBBRRBBBBRBBB...  test   HG01632   \n",
       "20013  RMRRRRRRRRRRRRRRRRFRRRRFRRRRRRMRRRRMRRRRRRRMRR...  test   HG00173   \n",
       "20014  RRRRRRRRRRRRRRRRRRRRRRRRRRRRRRBBRRBRRRRRRRRRRR...  test   HG00178   \n",
       "\n",
       "                seg_name  seg_label  \n",
       "20010  ENSG00000198502.5          4  \n",
       "20011  ENSG00000214425.1          1  \n",
       "20012  ENSG00000176681.9          9  \n",
       "20013  ENSG00000238083.3          0  \n",
       "20014  ENSG00000229450.2          3  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82414099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CUDA device: CPU\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print('\\nCUDA device: GPU\\n')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('\\nCUDA device: CPU\\n')\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "#os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:512\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa14ba6a",
   "metadata": {},
   "source": [
    "**1. Dataset and Dataloader**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f11c457",
   "metadata": {},
   "source": [
    "Define Dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "597bf5fb-c432-4eec-93da-17d6f10af4e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SeqDataset(Dataset):\n",
    "\n",
    "    def __init__(self, seq_df, transform, max_augm_shift=0, \n",
    "                 mode='train'):\n",
    "        if input_params.dataset.endswith('.fa'):\n",
    "            self.fasta = pysam.FastaFile(input_params.dataset)\n",
    "        else:\n",
    "            self.fasta = None\n",
    "\n",
    "        self.seq_df = seq_df\n",
    "        self.transform = transform\n",
    "        self.max_augm_shift = max_augm_shift\n",
    "        self.mode = mode\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq_df) # use original dataset length!\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.fasta:\n",
    "            seq = self.fasta.fetch(self.seq_df.iloc[idx].seq_name).upper()\n",
    "        else:\n",
    "            seq = self.seq_df.iloc[idx].seq.upper()\n",
    "\n",
    "        shift = np.random.randint(self.max_augm_shift+1) #random shift at training, must be chunk_size-input_params.seq_len\n",
    "\n",
    "        seq = seq[shift:shift+input_params.seq_len] #shift the sequence and limit its size\n",
    "        seg_label = self.seq_df.iloc[idx].seg_label #label for segment-aware training\n",
    "        \n",
    "        seq1 = seq.replace('-','').replace('B','A').replace('F','A').replace('M','R') # father\n",
    "        seq2 = seq.replace('-','').replace('B','A').replace('M','A').replace('F','R') # mother \n",
    "\n",
    "        masked_sequence1, target_labels_masked1, target_labels1, _, _ = self.transform(seq1)\n",
    "        masked_sequence2, target_labels_masked2, target_labels2, _, _ = self.transform(seq2)\n",
    "\n",
    "        masked_sequence = torch.vstack((masked_sequence1, masked_sequence2))\n",
    "        seg_label = torch.vstack((torch.tensor(seg_label), torch.tensor(seg_label)))\n",
    "        masked_sequence = (masked_sequence, seg_label)\n",
    "\n",
    "        target_labels_masked = torch.vstack((target_labels_masked1, target_labels_masked2))\n",
    "        target_labels = torch.vstack((target_labels1, target_labels2))\n",
    "        seq = (seq1, seq2)\n",
    "        return masked_sequence, target_labels_masked, target_labels, seq\n",
    "        \n",
    "        '''\n",
    "        #for given genotype, randomly choose a haplotype for training/testing\n",
    "        if np.random.rand()>0.5:\n",
    "            seq = seq.replace('-','').replace('B','A').replace('F','A').replace('M','R')\n",
    "        else:\n",
    "            seq = seq.replace('-','').replace('B','A').replace('M','A').replace('F','R')\n",
    "\n",
    "        #if input_params.masking == 'stratified_maf' and not input_params.test:\n",
    "        #    #select mask for the sequence depending on sequence coordinates w.r.t. contig\n",
    "        #    seg_name = self.seq_df.iloc[idx].seg_name\n",
    "        #    seq_mask = meta.loc[seg_name].MASK.values\n",
    "        #    masked_sequence, target_labels_masked, target_labels, _, _ = self.transform(seq, mask = seq_mask)\n",
    "        #else:\n",
    "        #    masked_sequence, target_labels_masked, target_labels, _, _ = self.transform(seq)\n",
    "\n",
    "        masked_sequence, target_labels_masked, target_labels, _, _ = self.transform(seq)\n",
    "\n",
    "        masked_sequence = (masked_sequence, seg_label)\n",
    "        return masked_sequence, target_labels_masked, target_labels, seq\n",
    "        '''\n",
    "\n",
    "    def close(self):\n",
    "        self.fasta.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af5510de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(data): \n",
    "    #masked sequence\n",
    "    masked_sequence = [x[0][0] for x in data]\n",
    "    masked_sequence = [torch.stack(torch.split(d, 3)) for d in masked_sequence] \n",
    "    masked_sequence = torch.concat(masked_sequence)\n",
    "    #seg labels\n",
    "    seg_labels = [x[0][1] for x in data]\n",
    "    seg_labels = torch.concat(seg_labels).flatten()\n",
    "    # target labels masked\n",
    "    target_labels_masked = [x[1] for x in data]\n",
    "    target_labels_masked = torch.concat(target_labels_masked)\n",
    "    # target labels \n",
    "    target_labels = [x[2] for x in data]\n",
    "    target_labels = torch.concat(target_labels)\n",
    "    #seq\n",
    "    seqs = [x[3] for x in data]\n",
    "    seqs = tuple(chain.from_iterable(seqs))\n",
    "    return (masked_sequence, seg_labels),target_labels_masked, target_labels, seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03fa3c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn_get_embeddings(data): \n",
    "    # masked sequence\n",
    "    masked_sequence = [x[0][0] for x in data]\n",
    "    # 50 = mask_stride of sequence_encoders.RollingMasker\n",
    "    masked_sequence = [torch.stack(torch.split(d, split_size_or_sections=50, dim = 0)) for d in masked_sequence]\n",
    "    masked_sequence = torch.concat(masked_sequence)\n",
    "    # seg labels\n",
    "    seg_labels = [x[0][1] for x in data]\n",
    "    seg_labels = torch.concat(seg_labels).flatten()\n",
    "    # target labels masked\n",
    "    target_labels_masked = [x[1] for x in data]\n",
    "    target_labels_masked = [torch.stack(torch.split(d, split_size_or_sections=50, dim = 0)) for d in target_labels_masked] \n",
    "    target_labels_masked = torch.concat(target_labels_masked)\n",
    "    # target labels \n",
    "    target_labels = [x[2] for x in data]\n",
    "    target_labels = [torch.stack(torch.split(d, split_size_or_sections=50, dim = 0)) for d in target_labels]\n",
    "    target_labels = torch.concat(target_labels)\n",
    "    #seq\n",
    "    seqs = [x[3] for x in data]\n",
    "    seqs = tuple(chain.from_iterable(seqs))     \n",
    "    return (masked_sequence, seg_labels), target_labels_masked, target_labels, seqs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15637814",
   "metadata": {},
   "source": [
    "Create Dataset and Dataloader for the data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98ce1c8b-d70c-4fe7-ac01-e86fd30a8dea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df = None \n",
    "\n",
    "if not input_params.test: #Train and Validate\n",
    "    seq_transform = sequence_encoders.SequenceDataEncoder(seq_len = input_params.seq_len, total_len = input_params.seq_len,\n",
    "                                                      mask_rate = input_params.mask_rate, split_mask = input_params.split_mask)\n",
    "\n",
    "    #N_train = int(len(seq_df)*(1-input_params.val_fraction))\n",
    "    if input_params.fold is not None:\n",
    "        \n",
    "        samples = seq_df.sample_id.unique()\n",
    "        val_samples = samples[input_params.fold::input_params.Nfolds] \n",
    "        train_df = seq_df[~seq_df.sample_id.isin(val_samples)] \n",
    "        test_df = seq_df[seq_df.sample_id.isin(val_samples)]\n",
    "        test_dataset = SeqDataset(test_df, transform = seq_transform, mode='eval')\n",
    "        test_dataloader = DataLoader(dataset = test_dataset, batch_size = input_params.batch_size, num_workers = 0, collate_fn = collate_fn, shuffle = False)\n",
    "    else:\n",
    "        train_df = seq_df\n",
    "        #train_df = seq_df[seq_df.split=='train']\n",
    "        #test_df = seq_df[seq_df.split=='val']\n",
    "  \n",
    "    N_train = len(train_df)\n",
    "    train_fold = np.repeat(list(range(input_params.train_splits)),repeats = N_train // input_params.train_splits + 1 )\n",
    "    train_df['train_fold'] = train_fold[:N_train]\n",
    "    # create training dataset & dataloader \n",
    "    train_dataset = SeqDataset(train_df, transform = seq_transform,  mode='train')\n",
    "    train_dataloader = DataLoader(dataset = train_dataset, batch_size = input_params.batch_size, num_workers = 2, collate_fn = collate_fn, shuffle = False)\n",
    "\n",
    "elif input_params.get_embeddings:\n",
    "    if input_params.mask_at_test:\n",
    "        seq_transform = sequence_encoders.RollingMasker(mask_stride = 50, frame = 0)\n",
    "    else:\n",
    "        seq_transform = sequence_encoders.PlainOneHot(frame = 0, padding = 'none')\n",
    "    # create test dataset & dataloader \n",
    "    test_dataset = SeqDataset(seq_df, transform = seq_transform, mode='eval')\n",
    "    test_dataloader = DataLoader(dataset = test_dataset, batch_size = 1, num_workers = 1, collate_fn = collate_fn_get_embeddings, shuffle = False)\n",
    "\n",
    "else: #Test\n",
    "    seq_transform = sequence_encoders.SequenceDataEncoder(seq_len = input_params.seq_len, total_len = input_params.seq_len,\n",
    "                                                      mask_rate=input_params.mask_rate, split_mask = input_params.split_mask)\n",
    "    # create test dataset & dataloader \n",
    "    test_dataset = SeqDataset(seq_df, transform = seq_transform, mode='eval')\n",
    "    test_dataloader = DataLoader(dataset = test_dataset, batch_size = input_params.batch_size, num_workers = 2, collate_fn = collate_fn, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11d82217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (masked_sequence, species_label), targets_masked, targets, _ = next(iter(test_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92832778",
   "metadata": {},
   "source": [
    "**2. Define model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad86179c-11e5-4b3b-a389-b8ab1b00bdbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seg_encoder = SpecAdd(embed = True, encoder = 'label', Nsegments=seq_df.seg_label.nunique(), d_model = input_params.d_model)\n",
    "\n",
    "model = DSSResNetEmb(d_input = 3, d_output = 3, d_model = input_params.d_model, n_layers = input_params.n_layers, \n",
    "                     dropout = input_params.dropout, embed_before = True, species_encoder = seg_encoder)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "model_params = [p for p in model.parameters() if p.requires_grad]\n",
    "\n",
    "optimizer = torch.optim.Adam(model_params, lr = input_params.learning_rate, weight_decay = input_params.weight_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806065f5",
   "metadata": {},
   "source": [
    "**3. Train model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec227158-c405-4dc7-8f6a-38a83009d725",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_epoch = 0\n",
    "\n",
    "if input_params.model_weight:\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        #load on gpu\n",
    "        model.load_state_dict(torch.load(input_params.model_weight))\n",
    "        if input_params.optimizer_weight:\n",
    "            optimizer.load_state_dict(torch.load(input_params.optimizer_weight))\n",
    "    else:\n",
    "        #load on cpu\n",
    "        model.load_state_dict(torch.load(input_params.model_weight, map_location=torch.device('cpu')))\n",
    "        if input_params.optimizer_weight:\n",
    "            optimizer.load_state_dict(torch.load(input_params.optimizer_weight, map_location=torch.device('cpu')))\n",
    "\n",
    "    last_epoch = int(input_params.model_weight.split('_')[-3]) #infer previous epoch from input_params.model_weight\n",
    "\n",
    "weights_dir = os.path.join(input_params.output_dir, 'weights') #dir to save model weights at save_at epochs\n",
    "\n",
    "if input_params.save_at:\n",
    "    os.makedirs(weights_dir, exist_ok = True)\n",
    "\n",
    "#lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,\n",
    "#        milestones=input_params.lr_sch_milestones, gamma=input_params.lr_sch_gamma, verbose=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f68efaa-d4a6-424f-a169-6d0d9046ec9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def metrics_to_str(metrics):\n",
    "    loss, accuracy, masked_acc, masked_recall, masked_IQS = metrics\n",
    "    return f'loss: {loss:.4}, acc: {accuracy:.4}, masked acc: {masked_acc:.4}, {misc.print_class_recall(masked_recall, \"masked recall: \")}, masked IQS: {masked_IQS:.4}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd086013-fd62-4964-8ccc-8b9d928d727d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 100: Test/Inference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                | 0/5030 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/stock/Documents/Uni/3.Semester/Systems_genetics/lm-eqtl/model/models/dss.py:335: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at /opt/conda/conda-bld/pytorch_1670525493953/work/aten/src/ATen/native/Copy.cpp:250.)\n",
      "  return einsum('chn,hnl->chl', W, S).float(), state                   # [C H L]\n",
      "/home/stockhaus/miniconda3/envs/sysgen/lib/python3.10/site-packages/torch/nn/functional.py:1338: UserWarning: dropout2d: Received a 3D input to dropout2d and assuming that channel-wise 1D dropout behavior is desired - input is interpreted as shape (N, C, L), where C is the channel dim. This behavior will change in a future release to interpret the input as one without a batch dimension, i.e. shape (C, H, W). To maintain the 1D channel-wise dropout behavior, please switch to using dropout1d instead.\n",
      "  warnings.warn(\"dropout2d: Received a 3D input to dropout2d and assuming that channel-wise \"\n",
      "acc: 0.9735, masked recall: R=0.974;A=0.916;AVG=0.948, masked acc: 0.9576, masked IQS: 0.9402, loss: 2.324:   0%|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       | 1/5030 [02:47<233:20:15, 167.03s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 45\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEPOCH \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlast_epoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: Test/Inference...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# test_metrics, test_embeddings, motif_probas =  train_eval.model_eval(model, optimizer, test_dataloader, device, \u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m#                                                       get_embeddings = input_params.get_embeddings, diploid = True,\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m#                                                       silent = False)\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m test_metrics, test_embeddings, motif_probas \u001b[38;5;241m=\u001b[39m  \u001b[43mtrain_eval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m                                                      \u001b[49m\u001b[43mget_embeddings\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minput_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiploid\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m                                                      \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlast_epoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - test, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics_to_str(test_metrics)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_params\u001b[38;5;241m.\u001b[39mget_embeddings:\n",
      "File \u001b[0;32m/mnt/c/Users/stock/Documents/Uni/3.Semester/Systems_genetics/lm-eqtl/model/helpers/train_eval.py:323\u001b[0m, in \u001b[0;36mmodel_eval\u001b[0;34m(model, dataloader, device, diploid, get_embeddings, temperature, silent)\u001b[0m\n\u001b[1;32m    320\u001b[0m criterion \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss(reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m diploid:\n\u001b[0;32m--> 323\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_eval_diploid\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mget_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m        \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    332\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m MaskedAccuracy()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    333\u001b[0m masked_recall \u001b[38;5;241m=\u001b[39m MeanRecall()\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m/mnt/c/Users/stock/Documents/Uni/3.Semester/Systems_genetics/lm-eqtl/model/helpers/train_eval.py:119\u001b[0m, in \u001b[0;36mmodel_eval_diploid\u001b[0;34m(model, dataloader, device, get_embeddings, temperature, silent)\u001b[0m\n\u001b[1;32m    116\u001b[0m targets2 \u001b[38;5;241m=\u001b[39m targets2\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    117\u001b[0m species_label \u001b[38;5;241m=\u001b[39m species_label\u001b[38;5;241m.\u001b[39mlong()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m--> 119\u001b[0m logits1, embeddings1 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmasked_sequence1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspecies_label\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m temperature:\n\u001b[1;32m    121\u001b[0m     logits1 \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m temperature\n",
      "File \u001b[0;32m~/miniconda3/envs/sysgen/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/c/Users/stock/Documents/Uni/3.Semester/Systems_genetics/lm-eqtl/model/models/spec_dss.py:212\u001b[0m, in \u001b[0;36mDSSResNetEmb.forward\u001b[0;34m(self, x, xs)\u001b[0m\n\u001b[1;32m    208\u001b[0m     x \u001b[38;5;241m=\u001b[39m z \u001b[38;5;241m+\u001b[39m x\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprenorm:\n\u001b[1;32m    211\u001b[0m         \u001b[38;5;66;03m# Postnorm\u001b[39;00m\n\u001b[0;32m--> 212\u001b[0m         x \u001b[38;5;241m=\u001b[39m norm(\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_before:\n\u001b[1;32m    216\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspecies_encoder(x,xs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "clear_output()\n",
    "\n",
    "#from helpers.misc import print    #print function that displays time\n",
    "\n",
    "if not input_params.test:\n",
    "    for epoch in range(last_epoch+1, input_params.tot_epochs+1):\n",
    "\n",
    "        print(f'EPOCH {epoch}: Training...')\n",
    "\n",
    "        #if input_params.masking == 'stratified_maf':\n",
    "\n",
    "        #    meta = get_random_mask()\n",
    "\n",
    "        train_dataset.seq_df = train_df[train_df.train_fold == (epoch-1) % input_params.train_splits]\n",
    "        print(f'using train samples: {list(train_dataset.seq_df.index[[0,-1]])}')\n",
    "\n",
    "        train_metrics = train_eval.model_train(model, optimizer, train_dataloader, device,\n",
    "                            silent = False)\n",
    "        \n",
    "        print(f'epoch {epoch} - train, {metrics_to_str(train_metrics)}')\n",
    "\n",
    "        if epoch in input_params.save_at: #save model weights\n",
    "\n",
    "            misc.save_model_weights(model, optimizer, weights_dir, epoch)\n",
    "\n",
    "        if test_df is not None  and ( epoch==input_params.tot_epochs or\n",
    "                            (input_params.validate_every and epoch%input_params.validate_every==0)):\n",
    "\n",
    "            print(f'EPOCH {epoch}: Validating...')\n",
    "\n",
    "            val_metrics, *_ =  train_eval.model_eval(model, optimizer, test_dataloader, device,\n",
    "                    silent = False)\n",
    "\n",
    "            print(f'epoch {epoch} - validation, {metrics_to_str(val_metrics)}')\n",
    "            \n",
    "        #lr_scheduler.step()\n",
    "else:\n",
    "    print(f'EPOCH {last_epoch}: Test/Inference...')\n",
    "\n",
    "    # test_metrics, test_embeddings, motif_probas =  train_eval.model_eval(model, optimizer, test_dataloader, device, \n",
    "    #                                                       get_embeddings = input_params.get_embeddings, diploid = True,\n",
    "    #                                                       silent = False)\n",
    "    test_metrics, test_embeddings, motif_probas =  train_eval.model_eval(model, test_dataloader, device, \n",
    "                                                          get_embeddings = input_params.get_embeddings, diploid = True,\n",
    "                                                          silent = False)\n",
    "    \n",
    "    \n",
    "\n",
    "    print(f'epoch {last_epoch} - test, {metrics_to_str(test_metrics)}')\n",
    "\n",
    "    if input_params.get_embeddings:\n",
    "        \n",
    "        os.makedirs(input_params.output_dir, exist_ok = True)\n",
    "\n",
    "        with open(input_params.output_dir + '/embeddings.pickle', 'wb') as f:\n",
    "            #test_embeddings = np.vstack(test_embeddings)\n",
    "            #np.save(f,test_embeddings)\n",
    "            pickle.dump(test_embeddings,f)\n",
    "            #pickle.dump(seq_df.seq_name.tolist(),f)\n",
    "            \n",
    "print()\n",
    "print(f'peak GPU memory allocation: {round(torch.cuda.max_memory_allocated(device)/1024/1024)} Mb')\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f34da63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7daa640a",
   "metadata": {},
   "source": [
    "### FOR TESTING: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a955316",
   "metadata": {},
   "source": [
    "(masked_sequence, species_label), targets_masked, targets, seq = next(iter(test_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bc81d8",
   "metadata": {},
   "source": [
    "from helpers.metrics import MeanRecall, MaskedAccuracy, IQS\n",
    "from helpers.misc import EMA, print_class_recall\n",
    "from torch.nn.functional import log_softmax\n",
    "\n",
    "temperature = None\n",
    "criterion = torch.nn.CrossEntropyLoss(reduction = \"mean\")\n",
    "\n",
    "accuracy = MaskedAccuracy().to(device)\n",
    "masked_recall = MeanRecall(Nclasses=4).to(device)\n",
    "masked_accuracy = MaskedAccuracy().to(device)\n",
    "masked_IQS = IQS(Nclasses=4).to(device)\n",
    "\n",
    "model.eval() #model to train mode\n",
    "avg_loss = 0.\n",
    "all_embeddings = []\n",
    "motif_probas = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    if True:\n",
    "        # with batch size = 1, one batch contains the two sequences of one sample \n",
    "        # let's extract both sequences and get the predictions of both \n",
    "        # afterwards compute the scores for the combined predictions \n",
    "        #masked sequence\n",
    "        masked_sequence1 = torch.split(masked_sequence, split_size_or_sections = 1, dim = 0)[0][0]\n",
    "        masked_sequence2 = torch.split(masked_sequence, split_size_or_sections = 1, dim = 0)[1][0]\n",
    "        # targets_masked\n",
    "        targets_masked1 = torch.split(targets_masked, split_size_or_sections = 1, dim = 0)[0][0]\n",
    "        targets_masked2 = torch.split(targets_masked, split_size_or_sections = 1, dim = 0)[1][0]\n",
    "        # targets \n",
    "        targets1 = torch.split(targets, split_size_or_sections = 1, dim = 0)[0][0]\n",
    "        targets2 = torch.split(targets, split_size_or_sections = 1, dim = 0)[1][0]\n",
    "        species_label = species_label[0]\n",
    "        species_label = species_label.tile((len(masked_sequence1),))\n",
    "\n",
    "        masked_sequence1 = masked_sequence1.to(device)\n",
    "        masked_sequence2 = masked_sequence2.to(device)\n",
    "        targets_masked1 = targets_masked1.to(device)\n",
    "        targets_masked2 = targets_masked2.to(device)\n",
    "        targets1 = targets1.to(device) \n",
    "        targets2 = targets2.to(device)   \n",
    "        species_label = species_label.long().to(device)\n",
    "\n",
    "        logits1, embeddings1 = model(masked_sequence1, species_label)\n",
    "        if temperature:\n",
    "            logits1 /= temperature\n",
    "        loss1 = criterion(logits1, targets_masked1)\n",
    "        avg_loss += loss1.item()\n",
    "        preds1 = torch.argmax(logits1, dim=1)\n",
    "\n",
    "        logits2, embeddings2 = model(masked_sequence2, species_label)\n",
    "        if temperature:\n",
    "            logits2 /= temperature\n",
    "        loss2 = criterion(logits2, targets_masked1)\n",
    "        avg_loss += loss2.item()\n",
    "        preds2 = torch.argmax(logits2, dim=1)\n",
    "\n",
    "        # \"notation\":\n",
    "        # 0 = R\n",
    "        # 1 = M \n",
    "        # 2 = F\n",
    "        # 3 = B \n",
    "        # -100 = masked \n",
    "         \n",
    "        # combine preds \n",
    "        combined_preds = preds1+preds2\n",
    "        combined_preds = torch.where(combined_preds==2, combined_preds +1, 0) # == 3 if both, 0 otherwise \n",
    "        temp = combined_preds + preds1 # == 4 if both, 1 if father \n",
    "        combined_preds = torch.where(temp==1, temp+1, combined_preds) # == 3 if both, 2 if father, otherwise 0 \n",
    "        temp = combined_preds + preds2 # == 4 if both, 2 if father, 1 if mother \n",
    "        combined_preds = torch.where(temp==1, temp, combined_preds) # == 3 if both, 2 if father, 1 if mother, otherwise 0 \n",
    "\n",
    "        # combine targets\n",
    "        combined_targets = targets1+targets2\n",
    "        combined_targets = torch.where(combined_targets==2, combined_targets +1, 0) # == 3 if both, 0 otherwise \n",
    "        temp = combined_targets + targets1 # == 4 if both, 1 if father \n",
    "        combined_targets = torch.where(temp==1, temp+1, combined_targets) # == 3 if both, 2 if father, otherwise 0 \n",
    "        temp = combined_targets + targets2 # == 4 if both, 2 if father, 1 if mother \n",
    "        combined_targets = torch.where(temp==1, temp, combined_targets) # == 3 if both, 2 if father, 1 if mother, otherwise 0 \n",
    "\n",
    "        # combine masked targets \n",
    "        combined_targets_masked = targets_masked1+targets_masked2\n",
    "        combined_targets_masked = torch.where(combined_targets_masked==2, combined_targets_masked +1, 0) # == 3 if both, 0 otherwise \n",
    "        temp = combined_targets_masked + targets_masked1 # == 4 if both, 1 if father \n",
    "        combined_targets_masked = torch.where(temp==1, temp+1, combined_targets_masked) # == 3 if both, 2 if father, otherwise 0 \n",
    "        temp = combined_targets_masked + targets_masked2 # == 4 if both, 2 if father, 1 if mother \n",
    "        combined_targets_masked = torch.where(temp==1, temp, combined_targets_masked) # == 3 if both, 2 if father, 1 if mother, otherwise 0 \n",
    "        combined_targets_masked = torch.where(temp==-100, temp, combined_targets_masked)# == 3 if both, 2 if father, 1 if mother, -100 if masked, otherwise 0 \n",
    "\n",
    "        accuracy.update(combined_preds, combined_targets)\n",
    "        masked_recall.update(combined_preds, combined_targets_masked)\n",
    "        masked_accuracy.update(combined_preds, combined_targets_masked)\n",
    "        masked_IQS.update(combined_preds, combined_targets_masked)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58086bfb",
   "metadata": {},
   "source": [
    "accuracy.compute(), masked_accuracy.compute(), masked_recall.compute(), masked_IQS.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b10d71b",
   "metadata": {},
   "source": [
    "# 0 = R\n",
    "# 1 = M \n",
    "# 2 = F\n",
    "# 3 = B "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bd4e65",
   "metadata": {},
   "source": [
    "# combine predictions\n",
    "combined_preds = preds1+preds2\n",
    "combined_preds = torch.where(combined_preds==2, combined_preds +1, 0) # == 3 if both, 0 otherwise \n",
    "temp = combined_preds + preds1 # == 4 if both, 1 if father \n",
    "combined_preds = torch.where(temp==1, temp+1, combined_preds) # == 3 if both, 2 if father, otherwise 0 \n",
    "temp = combined_preds + preds2 # == 4 if both, 2 if father, 1 if mother \n",
    "combined_preds = torch.where(temp==1, temp, combined_preds) # == 3 if both, 2 if father, 1 if mother, otherwise 0 \n",
    "combined_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1481fb8c",
   "metadata": {},
   "source": [
    "# combine targets\n",
    "combined_targets = targets1+targets2\n",
    "combined_targets = torch.where(combined_targets==2, combined_targets +1, 0) # == 3 if both, 0 otherwise \n",
    "temp = combined_targets + targets1 # == 4 if both, 1 if father \n",
    "combined_targets = torch.where(temp==1, temp+1, combined_targets) # == 3 if both, 2 if father, otherwise 0 \n",
    "temp = combined_targets + targets2 # == 4 if both, 2 if father, 1 if mother \n",
    "combined_targets = torch.where(temp==1, temp, combined_targets) # == 3 if both, 2 if father, 1 if mother, otherwise 0 \n",
    "combined_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bd24c4",
   "metadata": {},
   "source": [
    "combined_targets_masked = targets_masked1+targets_masked2\n",
    "combined_targets_masked= torch.where(combined_targets_masked==2, combined_targets_masked, 0)\n",
    "# 1 = F\n",
    "temp = combined_targets_masked + targets_masked1\n",
    "combined_targets_masked = torch.where(temp==1, temp, combined_targets_masked)\n",
    "combined_targets_masked = torch.where(temp==-100, temp, combined_targets_masked)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbddc5e",
   "metadata": {},
   "source": [
    "# combine masked targets\n",
    "combined_targets_masked = targets_masked1+targets_masked2\n",
    "combined_targets_masked = torch.where(combined_targets_masked==2, combined_targets_masked +1, 0) # == 3 if both, 0 otherwise \n",
    "temp = combined_targets_masked + targets_masked1 # == 4 if both, 1 if father \n",
    "combined_targets_masked = torch.where(temp==1, temp+1, combined_targets_masked) # == 3 if both, 2 if father, otherwise 0 \n",
    "temp = combined_targets_masked + targets_masked2 # == 4 if both, 2 if father, 1 if mother \n",
    "combined_targets_masked = torch.where(temp==1, temp, combined_targets_masked) # == 3 if both, 2 if father, 1 if mother, otherwise 0 \n",
    "combined_targets_masked = torch.where(temp==-100, temp, combined_targets_masked)# == 3 if both, 2 if father, 1 if mother, -100 if masked, otherwise 0 \n",
    "combined_targets_masked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70608ca0",
   "metadata": {},
   "source": [
    "targets_masked1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857a156b",
   "metadata": {},
   "source": [
    "targets_masked2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
